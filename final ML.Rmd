---
title: "final ML"
author: "Zac Macintyre"
date: "6/9/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(boot)
library(mltools)
library(data.table)
library(tidyverse)
library(caret)
library(leaps)
fires = read.csv("ForestFires.csv")
head(fires)
```

```{r}

colSums(is.na(fires))

```
As we said in the presentation there is no missing values just doing a little check

# This section is me doing some initial data visualization and somre data analysis

```{r}
barplot(table(fires$month))
barplot(table(fires$day))
```
```{r}
summary(fires)
```

```{r}
par(mfrow=c(2,2))
plot(fires$rain, fires$area)
plot(fires$temp, fires$area)
plot(fires$FFMC, fires$area)
plot(fires$DMC, fires$area)
```
```{r}
par(mfrow=c(2,2))
plot(fires$DC, fires$area)
plot(fires$ISI, fires$area)
plot(fires$wind, fires$area)
plot(fires$RH, fires$area)
```

```{r}
fires_matirx = fires[,-c(3,4)]
corelation_m = cor(fires_matirx, use='pairwise.complete.obs')
lower = lower.tri(fires_matirx)
corelation_m
hist(corelation_m[lower], xlab = 'correlations of lower matrix')
```

# In this section I will start actually looking into some regression settings

This is for fires not using X,Y,Day,Month
```{r}
fires_lm = fires[,-c(1,2,3,4)]
#head(fires_lm)
#fitting the most generic model
test = sample(nrow(fires_lm), floor(nrow(fires_lm)*.2))
linear_fit = glm(area ~., data = fires_lm[-test,])
summary(linear_fit)

#10 CV validation for the training set 
cv.glm(fires_lm[-test,], linear_fit, K = 10)$delta[1]

# getting MSE for the test
pred = predict(linear_fit, fires_lm[test,])
mean((pred - fires_lm[test, "area"])**2)
```


This is for fires not using Day,Month
```{r}
fires_lm = fires[,-c(3,4)]
#head(fires_lm)
#fitting the most generic model
test = sample(nrow(fires_lm), floor(nrow(fires_lm)*.2))
linear_fit = glm(area~., data = fires_lm[-test,])
summary(linear_fit)

#10 CV validation for the training set 
cv.glm(fires_lm[-test,], linear_fit, K = 10)$delta[1]

# getting MSE for the test
pred = predict(linear_fit, fires_lm[test,])
mean((pred - fires_lm[test, "area"])**2)
```


```{r}
fires$month = as.factor(fires$month)
fires$day = as.factor(fires$day)
newdata = one_hot(as.data.table(fires))
newdata
```

```{r}
test = sample(nrow(fires_lm), floor(nrow(fires_lm)*.2))
linear_fit = glm(area~., data = newdata[-test,])
summary(linear_fit)

#10 CV validation for the training set 
cv.glm(fires_lm[-test,], linear_fit, K = 10)$delta[1]

# getting MSE for the test
pred = predict(linear_fit, newdata[test,])
mean((pred - fires_lm[test, "area"])**2)
```


Trying different sub-selection models now
```{r}
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(area ~., data = newdata,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:28),
                    trControl = train.control
                    )
step.model$results

step.model$bestTune
summary(step.model$finalModel)
```

Usiing the above forward selection method we got that temp was the best forward selection model.  Here is code of us actually checking the MSE for temp
```{r}
test = sample(nrow(fires_lm), floor(nrow(fires_lm)*.2))
linear_fit = glm(area~temp, data = newdata[-test,])

# getting MSE for the test
pred = predict(linear_fit, newdata[test,])
mean((pred - fires_lm[test, "area"])**2)
```


```{r}

# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(area ~., data = newdata,
                    method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:28),
                    trControl = train.control
                    )
step.model$results

step.model$bestTune
summary(step.model$finalModel)
```

Temp was also the best selection for backwards selection



```{r}
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(area ~., data = newdata,
                    method = "leapSeq", 
                    tuneGrid = data.frame(nvmax = 1:10),
                    trControl = train.control
                    )
step.model$results

step.model$bestTune
summary(step.model$finalModel)
```
Still getting just the one variable model with only temp


```{r}
summary(lm(area ~ temp*day_sat, newdata))
```














